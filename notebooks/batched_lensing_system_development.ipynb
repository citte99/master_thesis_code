{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MassComponent(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "            We unpack the tensor configuration in the common features\n",
    "            between different mass components.\n",
    "\n",
    "            In this code, all the components are at same redshift, so the\n",
    "            redshift is not a parameter of the mass component.\n",
    "\n",
    "            We have only the position.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "    def deflection_angle(self, lens_grid, z_source):\n",
    "        \"\"\"\n",
    "           This forward computes the deflection field of the mass component\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    import torch\n",
    "\n",
    "import shared_utils.units as units\n",
    "\n",
    "import shared_utils.units as units\n",
    "\n",
    "class SIS(MassComponent):\n",
    "    def __init__(self, input_tensor=None, device=\"cuda\", dtype=torch.float32):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.dtype = dtype\n",
    "        \n",
    "        # Store compute precision constants for reuse\n",
    "        self.compute_dtype = torch.float32\n",
    "        self.c = torch.tensor(units.c, device=device, dtype=self.compute_dtype)\n",
    "        self.pi4 = torch.tensor(4 * torch.pi, device=device, dtype=self.compute_dtype)\n",
    "        self.epsilon = torch.tensor(1e-8, device=device, dtype=self.compute_dtype)\n",
    "        self.zero = torch.tensor(0.0, device=device, dtype=self.compute_dtype)\n",
    "        \n",
    "        if input_tensor is not None:\n",
    "            # Convert input tensor to compute precision directly\n",
    "            self.input_tensor = input_tensor.to(device=device, dtype=self.compute_dtype)\n",
    "            \n",
    "            # Extract parameters (all in compute precision)\n",
    "            self.pos = self.input_tensor[:, :2]\n",
    "            self.redshift = self.input_tensor[:, 2]\n",
    "            self.vel_disp = self.input_tensor[:, 3]\n",
    "            self.D_ls = self.input_tensor[:, 4]\n",
    "            self.D_s = self.input_tensor[:, 5]\n",
    "            \n",
    "            # Pre-compute Einstein angle (most expensive calculation)\n",
    "            vel_disp_c = self.vel_disp / self.c\n",
    "            squared = vel_disp_c ** 2\n",
    "            D_ratio = self.D_ls / self.D_s\n",
    "            self.einstein_angle = self.pi4 * squared * D_ratio\n",
    "        else:\n",
    "            self.input_tensor = None\n",
    "        \n",
    "        # Buffers will be allocated on first use\n",
    "        self._initialized_buffers = False\n",
    "        self._buffer_shapes = None\n",
    "    \n",
    "    def _initialize_buffers(self, batch_size, height, width):\n",
    "        \"\"\"Initialize all buffers at once with compute precision\"\"\"\n",
    "        # Only initialize once for each shape configuration\n",
    "        current_shapes = (batch_size, height, width)\n",
    "        if self._initialized_buffers and self._buffer_shapes == current_shapes:\n",
    "            return\n",
    "            \n",
    "        # Create all buffers in compute precision directly\n",
    "        self._x_rel = torch.empty((batch_size, height, width, 2), \n",
    "                                  device=self.device, dtype=self.compute_dtype)\n",
    "        self._r_squared = torch.empty((batch_size, height, width), \n",
    "                                      device=self.device, dtype=self.compute_dtype)\n",
    "        self._r = torch.empty((batch_size, height, width, 1), \n",
    "                             device=self.device, dtype=self.compute_dtype)\n",
    "        self._result = torch.empty((batch_size, height, width, 2), \n",
    "                                  device=self.device, dtype=self.compute_dtype)\n",
    "        \n",
    "        self._initialized_buffers = True\n",
    "        self._buffer_shapes = current_shapes\n",
    "\n",
    "    @torch.jit.script_method\n",
    "    def deflection_angle(self, lens_grid, z_source=None):\n",
    "        \"\"\"Optimized implementation using pre-allocated buffers and minimizing type conversions\"\"\"\n",
    "        # Upcast input grid once if needed\n",
    "        lens_grid_f32 = lens_grid if lens_grid.dtype == self.compute_dtype else lens_grid.to(dtype=self.compute_dtype)\n",
    "        \n",
    "        # Get dimensions\n",
    "        batch_size, height, width, _ = lens_grid_f32.shape\n",
    "        \n",
    "        # Ensure buffers are initialized\n",
    "        self._initialize_buffers(batch_size, height, width)\n",
    "        \n",
    "        # Calculate relative positions (in-place)\n",
    "        pos_expanded = self.pos.view(batch_size, 1, 1, 2)\n",
    "        torch.sub(lens_grid_f32, pos_expanded, out=self._x_rel)\n",
    "        \n",
    "        # Calculate squared distances (in-place)\n",
    "        x_rel_x = self._x_rel[..., 0]\n",
    "        x_rel_y = self._x_rel[..., 1]\n",
    "        torch.mul(x_rel_x, x_rel_x, out=self._r_squared)\n",
    "        torch.addcmul(self._r_squared, x_rel_y, x_rel_y, value=1.0, out=self._r_squared)\n",
    "        \n",
    "        # Calculate r with safe division (in-place)\n",
    "        torch.sqrt(self._r_squared, out=self._r.squeeze(-1))\n",
    "        torch.maximum(self._r.squeeze(-1), self.epsilon, out=self._r.squeeze(-1))\n",
    "        self._r = self._r.view(batch_size, height, width, 1)\n",
    "        \n",
    "        # Einstein angle already in compute precision, reshape for broadcasting\n",
    "        einstein_angle_expanded = self.einstein_angle.view(batch_size, 1, 1, 1)\n",
    "        \n",
    "        # Calculate deflection result directly (in-place)\n",
    "        torch.mul(einstein_angle_expanded, self._x_rel, out=self._result)\n",
    "        torch.div(self._result, self._r, out=self._result)\n",
    "        \n",
    "        # Convert to target precision only at the end\n",
    "        if self.dtype != self.compute_dtype:\n",
    "            result = self._result.to(dtype=self.dtype)\n",
    "        else:\n",
    "            result = self._result\n",
    "            \n",
    "        return result\n",
    "\n",
    "\n",
    "class NFW(MassComponent):\n",
    "    def __init__(self, input_tensor, device=\"cuda\", dtype=torch.float32):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.dtype = dtype\n",
    "        self.compute_dtype = torch.float32\n",
    "        \n",
    "        # Convert input tensor to compute precision directly\n",
    "        self.input_tensor = input_tensor.to(device=device, dtype=self.compute_dtype)\n",
    "        \n",
    "        # Extract parameters (all in compute precision)\n",
    "        self.pos = self.input_tensor[:, :2]\n",
    "        self.mass_max = self.input_tensor[:, 2]\n",
    "        self.r_max_kpc = self.input_tensor[:, 3]\n",
    "        self.D_l = self.input_tensor[:, 4] * 1000  # Convert to kpc immediately\n",
    "        self.D_s = self.input_tensor[:, 5] * 1000  # Convert to kpc immediately\n",
    "        self.D_ls = self.input_tensor[:, 6] * 1000  # Convert to kpc immediately\n",
    "\n",
    "        # Constants in compute precision\n",
    "        self.const = torch.tensor(2.16258, device=device, dtype=self.compute_dtype)\n",
    "        self.pi = torch.tensor(torch.pi, device=device, dtype=self.compute_dtype)\n",
    "        self.G = torch.tensor(units.G, device=device, dtype=self.compute_dtype)\n",
    "        self.c_squared = torch.tensor(units.c**2, device=device, dtype=self.compute_dtype)\n",
    "        self.epsilon = torch.tensor(1e-8, device=device, dtype=self.compute_dtype)\n",
    "        self.four = torch.tensor(4.0, device=device, dtype=self.compute_dtype)\n",
    "        self.two = torch.tensor(2.0, device=device, dtype=self.compute_dtype)\n",
    "        self.one = torch.tensor(1.0, device=device, dtype=self.compute_dtype)\n",
    "        self.zero = torch.tensor(0.0, device=device, dtype=self.compute_dtype)\n",
    "        \n",
    "        # Pre-compute derivable parameters (all in compute precision)\n",
    "        # r_s calculation\n",
    "        self.r_s = self.r_max_kpc / self.const\n",
    "        \n",
    "        # rho_s calculation\n",
    "        log_term = torch.log(1.0 + self.const)\n",
    "        const_term = self.const / (1.0 + self.const)\n",
    "        denominator = log_term - const_term\n",
    "        r_s_cubed = self.r_s ** 3\n",
    "        numerator = self.mass_max / (self.four * self.pi * r_s_cubed)\n",
    "        self.rho_s = numerator / denominator\n",
    "        \n",
    "        # Pre-compute sigma_crit\n",
    "        num = self.c_squared * self.D_s\n",
    "        denom = self.four * self.pi * self.G * self.D_l * self.D_ls\n",
    "        self.sigma_crit = num / denom\n",
    "        \n",
    "        # Pre-compute kappa_s\n",
    "        self.ks = (self.r_s * self.rho_s) / self.sigma_crit\n",
    "        \n",
    "        # Buffers will be allocated on first use\n",
    "        self._initialized_buffers = False\n",
    "        self._buffer_shapes = None\n",
    "    \n",
    "    def _initialize_buffers(self, batch_size, height, width):\n",
    "        \"\"\"Initialize all buffers at once with compute precision\"\"\"\n",
    "        # Only initialize once for each shape configuration\n",
    "        current_shapes = (batch_size, height, width)\n",
    "        if self._initialized_buffers and self._buffer_shapes == current_shapes:\n",
    "            return\n",
    "        \n",
    "        grid_shape = (batch_size, height, width)\n",
    "        \n",
    "        # Create all buffers in compute precision directly\n",
    "        self._xrel = torch.empty((batch_size, height, width, 2), \n",
    "                               device=self.device, dtype=self.compute_dtype)\n",
    "        self._rs2 = torch.empty(grid_shape, \n",
    "                              device=self.device, dtype=self.compute_dtype)\n",
    "        self._rs = torch.empty(grid_shape, \n",
    "                             device=self.device, dtype=self.compute_dtype)\n",
    "        self._rs_nodim = torch.empty(grid_shape, \n",
    "                                  device=self.device, dtype=self.compute_dtype)\n",
    "        self._F = torch.empty(grid_shape, \n",
    "                            device=self.device, dtype=self.compute_dtype)\n",
    "        self._log_term = torch.empty(grid_shape, \n",
    "                                  device=self.device, dtype=self.compute_dtype)\n",
    "        self._alpha = torch.empty(grid_shape, \n",
    "                                device=self.device, dtype=self.compute_dtype)\n",
    "        self._alpha_vec = torch.empty((batch_size, height, width, 2), \n",
    "                                   device=self.device, dtype=self.compute_dtype)\n",
    "        \n",
    "        self._initialized_buffers = True\n",
    "        self._buffer_shapes = current_shapes\n",
    "    \n",
    "    @torch.jit.script_method\n",
    "    def deflection_angle(self, lens_grid, z_source=None):\n",
    "        \"\"\"Optimized implementation using pre-allocated buffers and minimizing type conversions\"\"\"\n",
    "        # Upcast input grid once if needed\n",
    "        lens_grid_f32 = lens_grid if lens_grid.dtype == self.compute_dtype else lens_grid.to(dtype=self.compute_dtype)\n",
    "        \n",
    "        # Get dimensions\n",
    "        batch_size, height, width, _ = lens_grid_f32.shape\n",
    "        \n",
    "        # Ensure buffers are initialized\n",
    "        self._initialize_buffers(batch_size, height, width)\n",
    "        \n",
    "        # Calculate relative positions (in-place)\n",
    "        pos_expanded = self.pos.view(batch_size, 1, 1, 2)\n",
    "        torch.sub(lens_grid_f32, pos_expanded, out=self._xrel)\n",
    "        \n",
    "        # Calculate radius squared (in-place)\n",
    "        x_rel_x = self._xrel[..., 0]\n",
    "        x_rel_y = self._xrel[..., 1]\n",
    "        torch.mul(x_rel_x, x_rel_x, out=self._rs2)\n",
    "        torch.addcmul(self._rs2, x_rel_y, x_rel_y, value=1.0, out=self._rs2)\n",
    "        \n",
    "        # Calculate radius with safe division (in-place)\n",
    "        torch.sqrt(self._rs2, out=self._rs)\n",
    "        torch.maximum(self._rs, self.epsilon, out=self._rs)\n",
    "        \n",
    "        # Calculate rs_nodim (in-place)\n",
    "        D_l_expanded = self.D_l.view(-1, 1, 1)\n",
    "        r_s_expanded = self.r_s.view(-1, 1, 1)\n",
    "        torch.mul(self._rs, D_l_expanded, out=self._rs_nodim)\n",
    "        torch.div(self._rs_nodim, r_s_expanded, out=self._rs_nodim)\n",
    "        \n",
    "        # Reset F buffer (in-place)\n",
    "        self._F.zero_()\n",
    "        \n",
    "        # Get masks efficiently\n",
    "        mask1 = self._rs_nodim < 1\n",
    "        mask2 = self._rs_nodim == 1\n",
    "        mask3 = self._rs_nodim > 1\n",
    "        \n",
    "        # Handle each case\n",
    "        if mask1.any():\n",
    "            rs_nodim_mask1 = self._rs_nodim[mask1]\n",
    "            rs_nodim_sq = rs_nodim_mask1 * rs_nodim_mask1\n",
    "            sqrt_term1 = torch.sqrt(self.one - rs_nodim_sq)\n",
    "            F_values = torch.atanh(sqrt_term1) / sqrt_term1\n",
    "            self._F[mask1] = F_values\n",
    "        \n",
    "        if mask2.any():\n",
    "            self._F[mask2] = 1.0\n",
    "        \n",
    "        if mask3.any():\n",
    "            rs_nodim_mask3 = self._rs_nodim[mask3]\n",
    "            rs_nodim_sq = rs_nodim_mask3 * rs_nodim_mask3\n",
    "            sqrt_term3 = torch.sqrt(rs_nodim_sq - self.one)\n",
    "            F_values = torch.atan(sqrt_term3) / sqrt_term3\n",
    "            self._F[mask3] = F_values\n",
    "        \n",
    "        # Calculate log term (in-place)\n",
    "        torch.div(self._rs_nodim, self.two, out=self._log_term)\n",
    "        torch.log(self._log_term, out=self._log_term)\n",
    "        \n",
    "        # Calculate deflection magnitude (in-place)\n",
    "        ks_expanded = self.ks.view(batch_size, 1, 1)\n",
    "        r_s_expanded = self.r_s.view(-1, 1, 1)\n",
    "        D_l_expanded = self.D_l.view(-1, 1, 1)\n",
    "        \n",
    "        # Calculate the log_term + F value\n",
    "        torch.add(self._log_term, self._F, out=self._alpha)\n",
    "        \n",
    "        # Calculate full alpha formula\n",
    "        torch.mul(self._alpha, self.four * ks_expanded, out=self._alpha)\n",
    "        torch.mul(self._alpha, r_s_expanded, out=self._alpha)\n",
    "        torch.div(self._alpha, D_l_expanded * self._rs_nodim, out=self._alpha)\n",
    "        \n",
    "        # Calculate deflection vector (in-place)\n",
    "        alpha_expanded = self._alpha.view(batch_size, height, width, 1)\n",
    "        rs_expanded = self._rs.view(batch_size, height, width, 1)\n",
    "        torch.mul(alpha_expanded, self._xrel, out=self._alpha_vec)\n",
    "        torch.div(self._alpha_vec, rs_expanded, out=self._alpha_vec)\n",
    "        \n",
    "        # Convert to target precision only at the end\n",
    "        if self.dtype != self.compute_dtype:\n",
    "            result = self._alpha_vec.to(dtype=self.dtype)\n",
    "        else:\n",
    "            result = self._alpha_vec\n",
    "            \n",
    "        return result\n",
    "\n",
    "import torch\n",
    "from shared_utils import _arcsec_to_rad\n",
    "\n",
    "class ExternalPotential(MassComponent):\n",
    "    def __init__(self, input_tensor, device=\"cuda\"):\n",
    "        \"\"\"\n",
    "        For the ExternalPotential, the input tensor is expected to be of shape [B, 4]:\n",
    "            [[shear_center_x, shear_center_y, shear_strength, shear_angle_arcsec],\n",
    "             [shear_center_x, shear_center_y, shear_strength, shear_angle_arcsec],\n",
    "             ...]\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.input_tensor = input_tensor.to(self.device)\n",
    "        \n",
    "        # Extract batched parameters.\n",
    "        # shear_center: shape [B, 2]\n",
    "        self.shear_center = self.input_tensor[:, :2]\n",
    "        # shear_strength: shape [B]\n",
    "        self.ss = self.input_tensor[:, 2]\n",
    "        # Convert shear angle from arcseconds to radians.\n",
    "        self.sa = _arcsec_to_rad(self.input_tensor[:, 3])\n",
    "\n",
    "    def deflection_angle(self, lens_grid, precomp_dict=None, z_source=None):\n",
    "        \"\"\"\n",
    "        Compute the batched deflection angle for the external shear.\n",
    "        \n",
    "        Parameters:\n",
    "          lens_grid: Tensor of shape [B, H, W, 2] representing the grid in the lens plane.\n",
    "          precomp_dict: Dummy argument for uniformity with other mass components.\n",
    "          z_source: Dummy argument for clarity.\n",
    "          \n",
    "        Returns:\n",
    "          A tensor of deflection angles with shape [B, H, W, 2].\n",
    "        \"\"\"\n",
    "        # Reshape shear_center to [B, 1, 1, 2] for broadcasting.\n",
    "        shear_center = self.shear_center.view(-1, 1, 1, 2)\n",
    "        # Compute relative positions.\n",
    "        xrel = lens_grid - shear_center\n",
    "        \n",
    "        # Reshape shear strength and shear angle for broadcasting.\n",
    "        ss = self.ss.view(-1, 1, 1)\n",
    "        sa = self.sa.view(-1, 1, 1)\n",
    "        \n",
    "        # Compute cosine and sine terms for the shear transformation.\n",
    "        cs2 = -torch.cos(2 * sa)\n",
    "        sn2 = -torch.sin(2 * sa)\n",
    "        \n",
    "        # Compute the deflection angle components.\n",
    "        alpha_x = ss * (cs2 * xrel[..., 0] + sn2 * xrel[..., 1])\n",
    "        alpha_y = ss * (sn2 * xrel[..., 0] - cs2 * xrel[..., 1])\n",
    "        \n",
    "        # Stack the components to form the vector field.\n",
    "        alpha = torch.stack((alpha_x, alpha_y), dim=-1)\n",
    "        return alpha\n",
    "\n",
    "import torch\n",
    "\n",
    "def _hyp2f1_series(z, r2, t, q, max_terms=15):\n",
    "    \"\"\"\n",
    "    Batched implementation of the hypergeometric 2F1 series for the PEMD lens model.\n",
    "    \n",
    "    Parameters:\n",
    "      z       : Complex tensor of shape [B, ...] representing the (complex) coordinate.\n",
    "      r2      : Tensor of shape [B, ...] representing the squared elliptical radius.\n",
    "      t       : Tensor of shape [B, ...] representing the power-law slope.\n",
    "      q       : Tensor of shape [B, ...] representing the axis ratio.\n",
    "      max_terms: Maximum number of terms in the series expansion.\n",
    "      \n",
    "    Returns:\n",
    "      f       : Complex tensor of the same shape as z, containing the series evaluation.\n",
    "    \n",
    "    Note:\n",
    "      A warning is printed if any element of q is less than 0.8, since convergence\n",
    "      issues may occur in that regime.\n",
    "    \"\"\"\n",
    "    if (q < 0.8).any():\n",
    "        print(\"Warning: some q < 0.8 in this _hyp2f1_series implementation may not converge\")\n",
    "    \n",
    "    # Compute qp = (1 - q^2) / q^2, with q being batched.\n",
    "    qp = (1 - q**2) / q**2\n",
    "    # Compute w2 = qp * r2 / z^2. Division is elementwise.\n",
    "    w2 = qp * r2 / (z**2)\n",
    "    \n",
    "    # Compute u = 0.5 * (1 - sqrt(1 - w2))\n",
    "    u = 0.5 * (1.0 - torch.sqrt(1.0 - w2))\n",
    "    \n",
    "    # Initialize u_n and a_n as tensors of ones with the same shape (and type) as u.\n",
    "    u_n = torch.ones_like(u)  # u_n will accumulate powers of u\n",
    "    a_n = torch.ones_like(u)  # a_n accumulates the coefficient product\n",
    "    # Initialize the series sum.\n",
    "    f = a_n * u_n\n",
    "    \n",
    "    # Sum the series for max_terms iterations.\n",
    "    for n in range(max_terms):\n",
    "        u_n = u_n * u  # Increase power: u^(n+1)\n",
    "        # Compute the multiplier factor elementwise.\n",
    "        # Note: the operations are broadcasted against t.\n",
    "        num = (2 * n + 4) - 2 * t\n",
    "        den = (2 * n + 4) - t\n",
    "        a_n = a_n * (num / den)\n",
    "        f = f + a_n * u_n\n",
    "        \n",
    "    return f\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "class PEMD(MassComponent):\n",
    "    \"\"\"\n",
    "    Power-law elliptical mass distribution (PEMD).\n",
    "\n",
    "    In this version, the Einstein radius is computed on the fly\n",
    "    from the velocity dispersion and the precomputed angular distances.\n",
    "    \n",
    "    Input tensor is expected to be of shape [B, 8]:\n",
    "      [\n",
    "        [slope, pos_x, pos_y, orient, q, vel_disp, D_s, D_ls],\n",
    "        ...\n",
    "      ]\n",
    "    where:\n",
    "      - slope (t) is the power-law slope,\n",
    "      - pos is the lens center,\n",
    "      - orient is the lens orientation in radians,\n",
    "      - q is the axis ratio,\n",
    "      - vel_disp is the velocity dispersion in km/s,\n",
    "      - D_s is the source angular diameter distance (in Mpc),\n",
    "      - D_ls is the lens-to-source angular diameter distance (in Mpc).\n",
    "    \"\"\"\n",
    "    def __init__(self, input_tensor, device=\"cuda\"):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.input_tensor = input_tensor.to(self.device)\n",
    "        \n",
    "        # Extract batched parameters.\n",
    "        self.slope    = self.input_tensor[:, 0]        # [B]\n",
    "        self.pos      = self.input_tensor[:, 1:3]        # [B, 2]\n",
    "        self.th       = self.input_tensor[:, 3]          # [B] orientation (radians)\n",
    "        self.q        = self.input_tensor[:, 4]          # [B]\n",
    "        self.vel_disp = self.input_tensor[:, 5]          # [B] in km/s\n",
    "        self.D_s      = self.input_tensor[:, 6]          # [B] in Mpc\n",
    "        self.D_ls     = self.input_tensor[:, 7]          # [B] in Mpc\n",
    "        \n",
    "    def deflection_angle(self, lens_grid, precomp_dict=None, z_source=None):\n",
    "        \"\"\"\n",
    "        Compute the batched deflection angle for the PEMD profile.\n",
    "        \n",
    "        Parameters:\n",
    "          lens_grid: Tensor of shape [B, H, W, 2] representing the angular grid\n",
    "                     in the lens plane.\n",
    "          precomp_dict: Dummy argument (distances are provided in the input tensor).\n",
    "          z_source: Dummy argument.\n",
    "          \n",
    "        Returns:\n",
    "          A tensor of deflection angles of shape [B, H, W, 2].\n",
    "        \"\"\"\n",
    "        # Compute Einstein radius from velocity dispersion.\n",
    "        # For a SIS model: θ_E = 4π (vel_disp/c)² (D_ls/D_s)\n",
    "        # We assume c ~ 3e5 km/s.\n",
    "        c = torch.as_tensor(3e5, device=self.device)  # km/s\n",
    "        \n",
    "        # Reshape distances for broadcasting over the spatial grid.\n",
    "        D_s  = self.D_s.view(-1, 1, 1)   # [B, 1, 1] in Mpc\n",
    "        D_ls = self.D_ls.view(-1, 1, 1)  # [B, 1, 1] in Mpc\n",
    "        vel_disp = self.vel_disp.view(-1, 1, 1)  # [B, 1, 1] in km/s\n",
    "        \n",
    "        theta_E = 4 * torch.pi * (vel_disp / c)**2 * (D_ls / D_s)  # [B, 1, 1]\n",
    "        \n",
    "        # Compute the scale parameter b.\n",
    "        # The relation is taken as b = θ_E * √q.\n",
    "        q = self.q.view(-1, 1, 1)  # [B, 1, 1]\n",
    "        b = theta_E * torch.sqrt(q)  # [B, 1, 1]\n",
    "        \n",
    "        # Prepare the slope parameter for broadcasting.\n",
    "        t = self.slope.view(-1, 1, 1)  # [B, 1, 1]\n",
    "        \n",
    "        # Rotate coordinates:\n",
    "        # Subtract lens center and convert to complex form.\n",
    "        pos = self.pos.view(-1, 1, 1, 2)  # [B, 1, 1, 2]\n",
    "        diff = lens_grid - pos           # [B, H, W, 2]\n",
    "        z = torch.view_as_complex(diff)  # [B, H, W]\n",
    "        \n",
    "        # Apply orientation rotation.\n",
    "        th = self.th.view(-1, 1, 1)       # [B, 1, 1]\n",
    "        crot = torch.exp(-1j * th)\n",
    "        z = crot * z  # rotated coordinates\n",
    "        \n",
    "        # Compute the elliptical coordinate:\n",
    "        # rs² = q² * (Re(z))² + (Im(z))².\n",
    "        rs2 = (q**2) * (z.real**2) + (z.imag**2)  # [B, H, W]\n",
    "        rs = torch.sqrt(rs2)\n",
    "        \n",
    "        # Compute factor A = b² / (q * z) * (b / rs)^(t - 2)\n",
    "        A = (b**2) / (q * z) * (b / rs)**(t - 2)\n",
    "        \n",
    "        # Compute the hypergeometric series term.\n",
    "        F = _hyp2f1_series(z, rs2, t, q)\n",
    "        \n",
    "        # Compute the complex deflection angle and rotate back.\n",
    "        alpha_complex = torch.conj(A * F * crot)\n",
    "        \n",
    "        # Convert the complex deflection to a real 2-vector field.\n",
    "        alpha_real = torch.view_as_real(alpha_complex)\n",
    "        return alpha_real\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "\n",
    "class LensModel(nn.Module):\n",
    "    def __init__(self, config_list, precomp_dict_list, device=\"cuda\", dtype=torch.float32):\n",
    "        \"\"\"\n",
    "        Initialize the LensModel with batched mass components.\n",
    "        \n",
    "        Parameters:\n",
    "            config_list: List of dictionaries, each containing configuration for one lens system\n",
    "            precomp_dict_list: List of dictionaries with precomputed quantities for each system\n",
    "            device: Device to run computations on\n",
    "            dtype: Data type for tensor computations (torch.float32, torch.float16, etc.)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.dtype = dtype\n",
    "        self.num_systems = len(config_list)\n",
    "        self.precomp_dict_list = precomp_dict_list\n",
    "        \n",
    "        # Initialize component classes mapping\n",
    "        self.component_classes = {\n",
    "            \"SIS\": SIS,\n",
    "            \"NFW\": NFW,\n",
    "            \"ExternalPotential\": ExternalPotential,\n",
    "            \"PEMD\": PEMD\n",
    "        }\n",
    "        \n",
    "        # Process configurations and create batched components\n",
    "        self.process_configs(config_list)\n",
    "        \n",
    "    def process_configs(self, config_list):\n",
    "        \"\"\"\n",
    "        Process configuration list and create batched components\n",
    "        \"\"\"\n",
    "        # Group components by type\n",
    "        component_params = defaultdict(list)\n",
    "        self.system_indices = defaultdict(list)\n",
    "        \n",
    "        # Collect all components and their system indices\n",
    "        for sys_idx, config in enumerate(config_list):\n",
    "            mass_components = config.get(\"mass_components\", [])\n",
    "            for comp_config in mass_components:\n",
    "                comp_type = comp_config[\"type\"]\n",
    "                # Skip unknown component types\n",
    "                if comp_type not in self.component_classes:\n",
    "                    continue\n",
    "                    \n",
    "                # Add params and system index\n",
    "                component_params[comp_type].append((comp_config[\"params\"], self.precomp_dict_list[sys_idx]))\n",
    "                self.system_indices[comp_type].append(sys_idx)\n",
    "        \n",
    "        # Create batched components\n",
    "        self.components = {}\n",
    "        for comp_type, params_list in component_params.items():\n",
    "            # Build parameter tensor for this component type\n",
    "            param_tensor = self.build_param_tensor(comp_type, params_list)\n",
    "            \n",
    "            # Create the component, passing both device and dtype\n",
    "            self.components[comp_type] = self.component_classes[comp_type](\n",
    "                param_tensor, device=self.device, dtype=self.dtype)\n",
    "            \n",
    "            # Convert system indices to tensor\n",
    "            self.system_indices[comp_type] = torch.tensor(\n",
    "                self.system_indices[comp_type], device=self.device)\n",
    "    \n",
    "    def build_param_tensor(self, comp_type, params_list):\n",
    "        \"\"\"\n",
    "        Build parameter tensor for a specific component type with the specified dtype\n",
    "        \"\"\"\n",
    "        param_rows = []\n",
    "        \n",
    "        # Process the parameters based on component type\n",
    "        if comp_type == \"SIS\":\n",
    "            # Format: [x, y, redshift, vel_disp, D_ls, D_s]\n",
    "            for params, precomp in params_list:\n",
    "                param_rows.append([\n",
    "                    params[\"pos\"][0], params[\"pos\"][1], \n",
    "                    params[\"redshift\"], params[\"vel_disp\"],\n",
    "                    precomp[\"D_ls\"], precomp[\"D_s\"]\n",
    "                ])\n",
    "                \n",
    "        elif comp_type == \"NFW\":\n",
    "            # Format: [x, y, mass_max, r_max_kpc, D_l, D_s, D_ls]\n",
    "            for params, precomp in params_list:\n",
    "                param_rows.append([\n",
    "                    params[\"pos\"][0], params[\"pos\"][1],\n",
    "                    params[\"mass_max\"], params[\"r_max_kpc\"],\n",
    "                    precomp[\"D_l\"], precomp[\"D_s\"], precomp[\"D_ls\"]\n",
    "                ])\n",
    "                \n",
    "        elif comp_type == \"ExternalPotential\":\n",
    "            # Format: [shear_center_x, shear_center_y, shear_strength, shear_angle_arcsec]\n",
    "            for params, _ in params_list:\n",
    "                param_rows.append([\n",
    "                    params[\"shear_center\"][0], params[\"shear_center\"][1],\n",
    "                    params[\"shear_strength\"], params[\"shear_angle_arcsec\"]\n",
    "                ])\n",
    "                \n",
    "        elif comp_type == \"PEMD\":\n",
    "            # Format: [slope, pos_x, pos_y, orient, q, vel_disp, D_s, D_ls]\n",
    "            for params, precomp in params_list:\n",
    "                param_rows.append([\n",
    "                    params[\"slope\"], params[\"pos\"][0], params[\"pos\"][1], \n",
    "                    params[\"orient\"], params[\"q\"], params[\"vel_disp\"],\n",
    "                    precomp[\"D_s\"], precomp[\"D_ls\"]\n",
    "                ])\n",
    "        \n",
    "        # Convert to tensor with specified data type\n",
    "        return torch.tensor(param_rows, device=self.device, dtype=self.dtype)\n",
    "    \n",
    "    def deflection_field(self, lens_grid):\n",
    "        \"\"\"\n",
    "        Compute the deflection field for all systems\n",
    "        \"\"\"\n",
    "        # Ensure input grid is in the correct data type\n",
    "        if lens_grid.dtype != self.dtype:\n",
    "            lens_grid = lens_grid.to(dtype=self.dtype)\n",
    "            \n",
    "        # Initialize deflection field for all systems\n",
    "        batch_size, H, W, _ = lens_grid.shape\n",
    "        total_deflection = torch.zeros_like(lens_grid, dtype=self.dtype)\n",
    "        \n",
    "        # Calculate deflections for each component type\n",
    "        for comp_type, component in self.components.items():\n",
    "            # Get system indices for this component type\n",
    "            sys_indices = self.system_indices[comp_type]\n",
    "            \n",
    "            # Extract the relevant grid for each component instance\n",
    "            comp_grid = lens_grid[sys_indices]\n",
    "            \n",
    "            # Calculate deflection for this component type\n",
    "            comp_deflection = component.deflection_angle(comp_grid, z_source=None)\n",
    "            \n",
    "            # Add the deflection to the corresponding systems\n",
    "            for i, sys_idx in enumerate(sys_indices):\n",
    "                total_deflection[sys_idx] += comp_deflection[i]\n",
    "        \n",
    "        return total_deflection\n",
    "    \n",
    "    def forward(self, lens_grid):\n",
    "        \"\"\"\n",
    "        Calculate the source plane positions for all lens systems\n",
    "        \"\"\"\n",
    "        # Ensure input grid is in the correct data type\n",
    "        if lens_grid.dtype != self.dtype:\n",
    "            lens_grid = lens_grid.to(dtype=self.dtype)\n",
    "            \n",
    "        # Calculate the deflection field\n",
    "        deflection = self.deflection_field(lens_grid)\n",
    "        \n",
    "        # Calculate source plane positions\n",
    "        source_grid = lens_grid - deflection\n",
    "        \n",
    "        return source_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def _translate_rotate(x, xc, th_rad):\n",
    "    # Function remains unchanged as it already supports batched operations\n",
    "    return torch.view_as_real(torch.exp(-1j*th_rad)*torch.view_as_complex(x-xc))\n",
    "\n",
    "class SourceModel(nn.Module):\n",
    "    \"\"\"\n",
    "    The only initial constraint is the redshift of the source.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, source_grid):\n",
    "        \"\"\"\n",
    "        Compute the brightness of the source on the source grid.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "class GaussianBlob(SourceModel):\n",
    "    \"\"\"\n",
    "    Memory-efficient Gaussian blob source model\n",
    "    \"\"\"\n",
    "    def __init__(self, config_dict, precomp_dict, device):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        \n",
    "        # 1. Convert all parameters to tensors on device during initialization\n",
    "        if isinstance(config_dict[\"I\"], torch.Tensor):\n",
    "            self.I = config_dict[\"I\"].to(device)\n",
    "        else:\n",
    "            self.I = torch.tensor(config_dict[\"I\"], device=device, dtype=torch.float32)\n",
    "            \n",
    "        if isinstance(config_dict[\"position_rad\"], torch.Tensor):\n",
    "            self.position = config_dict[\"position_rad\"].to(device)\n",
    "        else:\n",
    "            self.position = torch.tensor(config_dict[\"position_rad\"], device=device, dtype=torch.float32)\n",
    "            \n",
    "        if isinstance(config_dict[\"orient_rad\"], torch.Tensor):\n",
    "            self.orient_rad = config_dict[\"orient_rad\"].to(device)\n",
    "        else:\n",
    "            self.orient_rad = torch.tensor(config_dict[\"orient_rad\"], device=device, dtype=torch.float32)\n",
    "            \n",
    "        if isinstance(config_dict[\"q\"], torch.Tensor):\n",
    "            self.q = config_dict[\"q\"].to(device)\n",
    "        else:\n",
    "            self.q = torch.tensor(config_dict[\"q\"], device=device, dtype=torch.float32)\n",
    "            \n",
    "        if isinstance(config_dict[\"std_kpc\"], torch.Tensor):\n",
    "            self.std_kpc = config_dict[\"std_kpc\"].to(device)\n",
    "        else:\n",
    "            self.std_kpc = torch.tensor(config_dict[\"std_kpc\"], device=device, dtype=torch.float32)\n",
    "            \n",
    "        # Convert D_s to tensor if needed\n",
    "        if isinstance(precomp_dict[\"D_s\"], torch.Tensor):\n",
    "            self.D_s = precomp_dict[\"D_s\"].to(device) * 1000.0  # Mpc to kpc\n",
    "        else:\n",
    "            self.D_s = torch.tensor(precomp_dict[\"D_s\"] * 1000.0, device=device, dtype=torch.float32)\n",
    "            \n",
    "        # Pre-compute std_rad\n",
    "        self.std_rad = self.std_kpc / self.D_s\n",
    "        \n",
    "        # 2. Constants for calculations\n",
    "        self.half = torch.tensor(0.5, device=device, dtype=torch.float32)\n",
    "        \n",
    "        # 3. Pre-allocate buffers for calculations\n",
    "        self._buffers = {\n",
    "            # Parameter expansion buffers\n",
    "            'position_expanded': None,\n",
    "            'orient_rad_expanded': None,\n",
    "            'q_expanded': None,\n",
    "            'std_rad_expanded': None,\n",
    "            'I_expanded': None,\n",
    "            \n",
    "            # Calculation buffers\n",
    "            'diff': None,        # For translate operation\n",
    "            'complex_z': None,   # For rotation operation\n",
    "            'rotated_z': None,   # For rotation result\n",
    "            'xrel': None,        # For rotated coordinates\n",
    "            'rs2': None,         # For squared distances\n",
    "            'exp_term': None,    # For exponent calculation\n",
    "            'sb': None           # For surface brightness\n",
    "        }\n",
    "        \n",
    "        # 4. Pre-allocate rotation factors\n",
    "        self._batch_sizes_seen = set()\n",
    "        self._rotation_factors = {}  # Cache for exp(-i*theta) for different batch sizes\n",
    "    \n",
    "    def _ensure_buffers(self, batch_size, height, width):\n",
    "        \"\"\"Initialize or resize buffers based on input dimensions\"\"\"\n",
    "        grid_shape = (batch_size, height, width)\n",
    "        \n",
    "        if (self._buffers['position_expanded'] is None or \n",
    "            self._buffers['position_expanded'].shape[0] != batch_size):\n",
    "            \n",
    "            # Parameter expansion buffers\n",
    "            self._buffers['position_expanded'] = torch.empty(\n",
    "                (batch_size, 1, 1, 2), device=self.device, dtype=torch.float32)\n",
    "            self._buffers['orient_rad_expanded'] = torch.empty(\n",
    "                (batch_size, 1, 1), device=self.device, dtype=torch.float32)\n",
    "            self._buffers['q_expanded'] = torch.empty(\n",
    "                (batch_size, 1, 1), device=self.device, dtype=torch.float32)\n",
    "            self._buffers['std_rad_expanded'] = torch.empty(\n",
    "                (batch_size, 1, 1), device=self.device, dtype=torch.float32)\n",
    "            self._buffers['I_expanded'] = torch.empty(\n",
    "                (batch_size, 1, 1), device=self.device, dtype=torch.float32)\n",
    "            \n",
    "            # Translation and rotation buffers\n",
    "            self._buffers['diff'] = torch.empty(\n",
    "                (batch_size, height, width, 2), device=self.device, dtype=torch.float32)\n",
    "            self._buffers['complex_z'] = torch.empty(\n",
    "                (batch_size, height, width), device=self.device, dtype=torch.complex64)\n",
    "            self._buffers['rotated_z'] = torch.empty(\n",
    "                (batch_size, height, width), device=self.device, dtype=torch.complex64)\n",
    "            self._buffers['xrel'] = torch.empty(\n",
    "                (batch_size, height, width, 2), device=self.device, dtype=torch.float32)\n",
    "            \n",
    "            # Brightness calculation buffers\n",
    "            self._buffers['rs2'] = torch.empty(\n",
    "                grid_shape, device=self.device, dtype=torch.float32)\n",
    "            self._buffers['exp_term'] = torch.empty(\n",
    "                grid_shape, device=self.device, dtype=torch.float32)\n",
    "            self._buffers['sb'] = torch.empty(\n",
    "                grid_shape, device=self.device, dtype=torch.float32)\n",
    "            \n",
    "            # Cache rotation factor for this batch size\n",
    "            if batch_size not in self._batch_sizes_seen:\n",
    "                self._batch_sizes_seen.add(batch_size)\n",
    "                self._rotation_factors[batch_size] = None\n",
    "    \n",
    "    def _get_rotation_factor(self, batch_size, orient_rad):\n",
    "        \"\"\"Get or compute rotation factor exp(-i*theta)\"\"\"\n",
    "        if self._rotation_factors[batch_size] is None:\n",
    "            self._rotation_factors[batch_size] = torch.empty(\n",
    "                (batch_size, 1, 1), device=self.device, dtype=torch.complex64)\n",
    "        \n",
    "        # Compute rotation factor (in-place when possible)\n",
    "        neg_i_theta = -1j * orient_rad\n",
    "        torch.exp(neg_i_theta, out=self._rotation_factors[batch_size])\n",
    "        \n",
    "        return self._rotation_factors[batch_size]\n",
    "    \n",
    "    def _optimized_translate_rotate(self, source_grid, position, orient_rad):\n",
    "        \"\"\"Memory-efficient implementation of translate and rotate\"\"\"\n",
    "        batch_size, height, width, _ = source_grid.shape\n",
    "        \n",
    "        # 1. Translation (in-place)\n",
    "        torch.sub(source_grid, position, out=self._buffers['diff'])\n",
    "        \n",
    "        # 2. View as complex for rotation\n",
    "        self._buffers['complex_z'] = torch.view_as_complex(\n",
    "            self._buffers['diff'].contiguous().view(batch_size, height, width, 1, 2)\n",
    "            .squeeze(-2))\n",
    "        \n",
    "        # 3. Get rotation factor and multiply (in-place)\n",
    "        rot_factor = self._get_rotation_factor(batch_size, orient_rad)\n",
    "        torch.mul(self._buffers['complex_z'], rot_factor, out=self._buffers['rotated_z'])\n",
    "        \n",
    "        # 4. Convert back to real coordinates\n",
    "        self._buffers['xrel'] = torch.view_as_real(self._buffers['rotated_z'])\n",
    "        \n",
    "        return self._buffers['xrel']\n",
    "    \n",
    "    def forward(self, source_grid):\n",
    "        \"\"\"Memory-efficient implementation of Gaussian blob\"\"\"\n",
    "        # Get dimensions\n",
    "        batch_size, height, width, _ = source_grid.shape\n",
    "        \n",
    "        # 1. Ensure buffers are allocated with correct shape\n",
    "        self._ensure_buffers(batch_size, height, width)\n",
    "        \n",
    "        # 2. Expand parameters efficiently (in-place)\n",
    "        # Expand position [2] → [B, 1, 1, 2]\n",
    "        pos_expanded = self._buffers['position_expanded']\n",
    "        pos_expanded.copy_(self.position.expand(batch_size, 2).view(batch_size, 1, 1, 2))\n",
    "        \n",
    "        # Expand scalars [1] → [B, 1, 1]\n",
    "        orient_expanded = self._buffers['orient_rad_expanded']\n",
    "        orient_expanded.copy_(self.orient_rad.expand(batch_size).view(batch_size, 1, 1))\n",
    "        \n",
    "        q_expanded = self._buffers['q_expanded']\n",
    "        q_expanded.copy_(self.q.expand(batch_size).view(batch_size, 1, 1))\n",
    "        \n",
    "        std_expanded = self._buffers['std_rad_expanded']\n",
    "        std_expanded.copy_(self.std_rad.expand(batch_size).view(batch_size, 1, 1))\n",
    "        \n",
    "        I_expanded = self._buffers['I_expanded']\n",
    "        I_expanded.copy_(self.I.expand(batch_size).view(batch_size, 1, 1))\n",
    "        \n",
    "        # 3. Calculate rotated coordinates efficiently\n",
    "        xrel = self._optimized_translate_rotate(\n",
    "            source_grid, pos_expanded, orient_expanded)\n",
    "        \n",
    "        # 4. Calculate squared distance (in-place)\n",
    "        rs2 = self._buffers['rs2']\n",
    "        rs2.zero_()\n",
    "        \n",
    "        # rs2 = q²·x² + y²\n",
    "        torch.pow(xrel[..., 0], 2, out=rs2)\n",
    "        torch.mul(rs2, q_expanded**2, out=rs2)\n",
    "        torch.addcmul(rs2, xrel[..., 1], xrel[..., 1], value=1.0, out=rs2)\n",
    "        \n",
    "        # 5. Calculate exponential term (in-place)\n",
    "        exp_term = self._buffers['exp_term']\n",
    "        torch.div(rs2, std_expanded**2, out=exp_term)\n",
    "        torch.mul(exp_term, -self.half, out=exp_term)\n",
    "        torch.exp(exp_term, out=exp_term)\n",
    "        \n",
    "        # 6. Calculate surface brightness (in-place)\n",
    "        sb = self._buffers['sb']\n",
    "        torch.mul(exp_term, I_expanded, out=sb)\n",
    "        \n",
    "        # Store for reference\n",
    "        self.surface_brightness = sb\n",
    "        \n",
    "        return sb\n",
    "    \n",
    "    def __del__(self):\n",
    "        \"\"\"Clean up buffers when object is deleted\"\"\"\n",
    "        # Clear all buffers\n",
    "        for key in self._buffers:\n",
    "            self._buffers[key] = None\n",
    "        \n",
    "        # Clear rotation factors\n",
    "        self._rotation_factors.clear()\n",
    "        self._batch_sizes_seen.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from shared_utils import recursive_to_tensor\n",
    "\n",
    "\n",
    "class LensingSystem(nn.Module):\n",
    "    \"\"\"\n",
    "    Lensing system that handles multiple lens configurations in a batch\n",
    "    \"\"\"\n",
    "    def __init__(self, config_list, device, dtype=torch.float32):\n",
    "        \"\"\"\n",
    "        Initialize the lensing system with multiple configurations\n",
    "        \n",
    "        Parameters:\n",
    "            config_list: List of configuration dictionaries, one per lens system\n",
    "            device: Device to run computations on\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.num_systems = len(config_list)\n",
    "        self.dtype = dtype\n",
    "        self.precision_sensitive_ops_dtype = torch.float32  #\n",
    "        \n",
    "        # Process configs and move to device\n",
    "        self.config_list = [recursive_to_tensor(config, device, datatype=dtype) for config in config_list]\n",
    "        \n",
    "        # Extract lens model configs and precomputed values\n",
    "        lens_model_list = [config[\"lens_model\"] for config in self.config_list]\n",
    "        precomp_dict_list = [config[\"precomputed\"] for config in self.config_list]\n",
    "        \n",
    "        # Create a single lens model for all systems\n",
    "        self.lens_model = LensModel(lens_model_list, precomp_dict_list, device=device, dtype=dtype)\n",
    "        \n",
    "        # Create source models for each system\n",
    "        self.source_models = nn.ModuleList()\n",
    "        source_mapping = {\n",
    "            \"Gaussian_blob\": GaussianBlob,\n",
    "        }\n",
    "        \n",
    "        # Create a source model for each system\n",
    "        for config in self.config_list:\n",
    "            source_type = config[\"source_model\"][\"type\"]\n",
    "            if source_type not in source_mapping:\n",
    "                raise ValueError(f\"Unknown source model type: {source_type}\")\n",
    "                \n",
    "            source_model = source_mapping[source_type](\n",
    "                config[\"source_model\"][\"params\"],\n",
    "                precomp_dict=config[\"precomputed\"],\n",
    "                device=device\n",
    "            )\n",
    "            self.source_models.append(source_model)\n",
    "            \n",
    "        # Store source redshifts\n",
    "        self.source_redshifts = [config[\"source_model\"][\"params\"][\"redshift\"] for config in self.config_list]\n",
    "        \n",
    "    def forward(self, lens_grid):\n",
    "        \"\"\"\n",
    "        Forward pass for all lens systems\n",
    "        \n",
    "        Parameters:\n",
    "            lens_grid: Tensor of shape [B, H, W, 2] where B is the batch size (number of systems)\n",
    "            \n",
    "        Returns:\n",
    "            Tensor of shape [B, H, W] with image plane intensities for all systems\n",
    "        \"\"\"\n",
    "        if lens_grid.dtype != self.dtype:\n",
    "            lens_grid = lens_grid.to(dtype=self.dtype)\n",
    "            print(\"converting lens grid to dtype\", self.dtype)\n",
    "            \n",
    "        # Get source plane positions for all systems\n",
    "        source_grid = self.lens_model(lens_grid)\n",
    "        \n",
    "        # Initialize output tensor\n",
    "        output_shape = source_grid.shape[:-1]  # [B, H, W]\n",
    "        output = torch.zeros(output_shape, device=self.device)\n",
    "        \n",
    "        # Process each system with its source model\n",
    "        for i, source_model in enumerate(self.source_models):\n",
    "            if i < lens_grid.shape[0]:  # Only process within batch size\n",
    "                system_source_grid = source_grid[i:i+1]  # [1, H, W, 2]\n",
    "                output[i] = source_model(system_source_grid).squeeze(0)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'ScriptMethodStub' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 97\u001b[0m\n\u001b[1;32m     95\u001b[0m     image\u001b[38;5;241m=\u001b[39mlensing_system(grid)\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m image\n\u001b[0;32m---> 97\u001b[0m image\u001b[38;5;241m=\u001b[39m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28mprint\u001b[39m(torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mmemory_summary())\n\u001b[1;32m    100\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mreset_peak_memory_stats()\n",
      "Cell \u001b[0;32mIn[5], line 95\u001b[0m, in \u001b[0;36mrun\u001b[0;34m()\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun\u001b[39m():\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;66;03m#with torch.no_grad():\u001b[39;00m\n\u001b[1;32m     94\u001b[0m     lensing_system\u001b[38;5;241m=\u001b[39mLensingSystem(config_list, device\u001b[38;5;241m=\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m---> 95\u001b[0m     image\u001b[38;5;241m=\u001b[39m\u001b[43mlensing_system\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m image\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1714\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1712\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1713\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1714\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1725\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1720\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1721\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1722\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1723\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1724\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1725\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1727\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1728\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 72\u001b[0m, in \u001b[0;36mLensingSystem.forward\u001b[0;34m(self, lens_grid)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconverting lens grid to dtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# Get source plane positions for all systems\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m source_grid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlens_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlens_grid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# Initialize output tensor\u001b[39;00m\n\u001b[1;32m     75\u001b[0m output_shape \u001b[38;5;241m=\u001b[39m source_grid\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# [B, H, W]\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1714\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1712\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1713\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1714\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1725\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1720\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1721\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1722\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1723\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1724\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1725\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1727\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1728\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 153\u001b[0m, in \u001b[0;36mLensModel.forward\u001b[0;34m(self, lens_grid)\u001b[0m\n\u001b[1;32m    150\u001b[0m     lens_grid \u001b[38;5;241m=\u001b[39m lens_grid\u001b[38;5;241m.\u001b[39mto(dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    152\u001b[0m \u001b[38;5;66;03m# Calculate the deflection field\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m deflection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeflection_field\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlens_grid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;66;03m# Calculate source plane positions\u001b[39;00m\n\u001b[1;32m    156\u001b[0m source_grid \u001b[38;5;241m=\u001b[39m lens_grid \u001b[38;5;241m-\u001b[39m deflection\n",
      "Cell \u001b[0;32mIn[2], line 136\u001b[0m, in \u001b[0;36mLensModel.deflection_field\u001b[0;34m(self, lens_grid)\u001b[0m\n\u001b[1;32m    133\u001b[0m comp_grid \u001b[38;5;241m=\u001b[39m lens_grid[sys_indices]\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m# Calculate deflection for this component type\u001b[39;00m\n\u001b[0;32m--> 136\u001b[0m comp_deflection \u001b[38;5;241m=\u001b[39m \u001b[43mcomponent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeflection_angle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcomp_grid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz_source\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m# Add the deflection to the corresponding systems\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, sys_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(sys_indices):\n",
      "\u001b[0;31mTypeError\u001b[0m: 'ScriptMethodStub' object is not callable"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from shared_utils import recursive_to_tensor, _grid_lens\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "\n",
    "device=\"cuda\"\n",
    "\n",
    "\n",
    "#Print detailed memory information\n",
    "\n",
    "\n",
    "def track_memory(label=\"\"):\n",
    "    print(f\"\\n--- MEMORY: {label} ---\")\n",
    "    print(torch.cuda.memory_summary())\n",
    "    print(f\"Allocated: {torch.cuda.memory_allocated()/1e6:.2f} MB\")\n",
    "    print(f\"Cached: {torch.cuda.memory_reserved()/1e6:.2f} MB\")\n",
    "\n",
    "\n",
    "one_image_dict={\n",
    "            \"system_index\": 0,\n",
    "            \"precomputed\": {\n",
    "                \"D_l\": 1717.9862002612902,\n",
    "                \"D_s\": 1518.4022740256946,\n",
    "                \"D_ls\": 761.5082718989717,\n",
    "                \"Theta_E\": 6.163572379738989e-06\n",
    "            },\n",
    "            \"lens_model\": {\n",
    "                \"num_substructures\": 1,\n",
    "                \"mass_components\": [\n",
    "                    {\n",
    "                        \"type\": \"SIS\",\n",
    "                        \"is_substructure\": False,\n",
    "                        \"params\": {\n",
    "                            \"pos\": [\n",
    "                                0.0,\n",
    "                                0.0\n",
    "                            ],\n",
    "                            \"redshift\": 1.0554628084028788,\n",
    "                            \"vel_disp\": 296.47503651129796\n",
    "                        }\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"NFW\",\n",
    "                        \"is_substructure\": True,\n",
    "                        \"params\": {\n",
    "                            \"pos\": [\n",
    "                                0.0,\n",
    "                                0.0\n",
    "                            ],\n",
    "                            \"mass_max\": 100000000000.0,\n",
    "                            \"r_max_kpc\": 1.0,\n",
    "                            \"redshift\": 1.0554628084028788\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            },\n",
    "            \"source_model\": {\n",
    "                \"type\": \"Gaussian_blob\",\n",
    "                \"params\": {\n",
    "                    \"I\": 1.0,\n",
    "                    \"position_rad\": [\n",
    "                        0.0,\n",
    "                        0.0\n",
    "                    ],\n",
    "                    \"orient_rad\": 0.0,\n",
    "                    \"q\": 0.8,\n",
    "                    \"std_kpc\": 0.1,\n",
    "                    \"redshift\": 3.6654574221282386\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "#one_image_dict=recursive_to_tensor(one_image_dict, device=device)\n",
    "\n",
    "batch_size=30\n",
    "grid = _grid_lens(6, 1000, device=device, dtype=torch.float32)\n",
    "grid = grid.unsqueeze(0).repeat(batch_size, 1, 1, 1) if len(grid.shape) == 3 else grid.repeat(batch_size, 1, 1, 1)\n",
    "\n",
    "from catalog_manager import CatalogManager\n",
    "my_catalog = CatalogManager(catalog_name_input=\"SIS_10e7_sub_train\")\n",
    "config_list=my_catalog.catalog[\"SL_systems\"][0: batch_size]\n",
    "config_list=[recursive_to_tensor(config, device) for config in config_list]\n",
    "# config_list=[]\n",
    "# for i in range(batch_size):\n",
    "#     config_list.append(one_image_dict)\n",
    "# #print(json.dumps(one_image_dict, indent=4))\n",
    "\n",
    "config_list=[recursive_to_tensor(config, device) for config in config_list]\n",
    "\n",
    "def run():\n",
    "    #with torch.no_grad():\n",
    "    lensing_system=LensingSystem(config_list, device=device, dtype=torch.float32)\n",
    "    image=lensing_system(grid)\n",
    "    return image\n",
    "image=run()\n",
    "\n",
    "print(torch.cuda.memory_summary())\n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "torch.cuda.reset_accumulated_memory_stats()  \n",
    "torch.cuda.empty_cache() \n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "#plt.imshow(image[1].cpu().detach().numpy())\n",
    "print(image.shape)\n",
    "\n",
    "\n",
    "\n",
    "# batch_sizes = [1, 10, 20, 30, 40]\n",
    "# for batch_size in batch_sizes:\n",
    "#     torch.cuda.empty_cache()  # Clear cache before each test\n",
    "#     track_memory(f\"Before batch_size={batch_size}\")\n",
    "    \n",
    "#     # Create system with batch_size\n",
    "#     grid = _grid_lens(6, 1000, device=device)\n",
    "#     grid = grid.unsqueeze(0).repeat(batch_size, 1, 1, 1)\n",
    "#     config_list = [one_image_dict] * batch_size\n",
    "    \n",
    "#     lensing_system = LensingSystem(config_list, device=device)\n",
    "#     track_memory(f\"After system creation batch_size={batch_size}\")\n",
    "    \n",
    "#     image = lensing_system(grid)\n",
    "#     track_memory(f\"After forward pass batch_size={batch_size}\")\n",
    "    \n",
    "#     del lensing_system, grid, image, config_list\n",
    "\n",
    "\n",
    "# batch_sizes = [1, 10, 20, 30, 40]\n",
    "# for batch_size in batch_sizes:\n",
    "#     # Create system with batch_size\n",
    "#     grid = _grid_lens(6, 100, device=device)\n",
    "#     grid = grid.unsqueeze(0).repeat(batch_size, 1, 1, 1)\n",
    "#     config_list = [one_image_dict] * batch_size\n",
    "    \n",
    "#     lensing_system = LensingSystem(config_list, device=device)\n",
    "    \n",
    "#     image = lensing_system(grid)\n",
    "    \n",
    "#     del lensing_system, grid, image, config_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          308 function calls (300 primitive calls) in 0.139 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.079    0.079    0.133    0.133 271530330.py:115(deflection_field)\n",
      "        1    0.033    0.033    0.051    0.051 2291391825.py:283(deflection_angle)\n",
      "        2    0.015    0.008    0.015    0.008 {built-in method torch.tensor}\n",
      "       23    0.001    0.000    0.001    0.000 {method 'copy_' of 'torch._C.TensorBase' objects}\n",
      "        1    0.001    0.001    0.002    0.002 2291391825.py:85(deflection_angle)\n",
      "       44    0.001    0.000    0.001    0.000 {built-in method torch.empty}\n",
      "        2    0.001    0.001    0.005    0.002 2768220853.py:165(forward)\n",
      "        7    0.001    0.000    0.001    0.000 {method 'pow' of 'torch._C.TensorBase' objects}\n",
      "        1    0.000    0.000    0.139    0.139 2877471766.py:57(forward)\n",
      "       28    0.000    0.000    0.000    0.000 {method 'view' of 'torch._C.TensorBase' objects}\n",
      "        3    0.000    0.000    0.000    0.000 {method 'any' of 'torch._C.TensorBase' objects}\n",
      "        8    0.000    0.000    0.000    0.000 {built-in method torch.mul}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method torch.pow}\n",
      "       55    0.000    0.000    0.000    0.000 {method 'to' of 'torch._C.TensorBase' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method torch.sub}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method torch.sqrt}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch.zeros_like}\n",
      "        5    0.000    0.000    0.000    0.000 {method 'zero_' of 'torch._C.TensorBase' objects}\n",
      "        2    0.000    0.000    0.001    0.001 2768220853.py:144(_optimized_translate_rotate)\n",
      "        2    0.000    0.000    0.000    0.000 2768220853.py:132(_get_rotation_factor)\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method torch.addcmul}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method torch.exp}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch.zeros}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method torch.div}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method torch.maximum}\n",
      "        1    0.000    0.000    0.133    0.133 271530330.py:144(forward)\n",
      "        1    0.000    0.000    0.139    0.139 {built-in method builtins.exec}\n",
      "       10    0.000    0.000    0.000    0.000 {method 'expand' of 'torch._C.TensorBase' objects}\n",
      "        6    0.000    0.000    0.000    0.000 {method 'squeeze' of 'torch._C.TensorBase' objects}\n",
      "      4/1    0.000    0.000    0.139    0.139 module.py:1718(_call_impl)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method torch.view_as_complex}\n",
      "        2    0.000    0.000    0.001    0.000 2768220853.py:90(_ensure_buffers)\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method torch._C._get_tracing_state}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch.atan}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'addcmul_' of 'torch._C.TensorBase' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'unbind' of 'torch._C.TensorBase' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch.log}\n",
      "        7    0.000    0.000    0.001    0.000 _tensor.py:33(wrapped)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch.atanh}\n",
      "        2    0.000    0.000    0.000    0.000 module.py:1897(__setattr__)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method torch.view_as_real}\n",
      "        2    0.000    0.000    0.000    0.000 _tensor.py:1040(__iter__)\n",
      "        2    0.000    0.000    0.000    0.000 parameter.py:10(__instancecheck__)\n",
      "        1    0.000    0.000    0.000    0.000 2291391825.py:248(_ensure_buffers)\n",
      "      4/1    0.000    0.000    0.139    0.139 module.py:1710(_wrapped_call_impl)\n",
      "        1    0.000    0.000    0.000    0.000 2291391825.py:68(_ensure_buffers)\n",
      "        2    0.000    0.000    0.000    0.000 module.py:1880(__getattr__)\n",
      "        1    0.000    0.000    0.000    0.000 container.py:345(__iter__)\n",
      "        7    0.000    0.000    0.000    0.000 {built-in method torch._C._has_torch_function}\n",
      "      6/4    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\n",
      "        1    0.000    0.000    0.139    0.139 <string>:1(<module>)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'contiguous' of 'torch._C.TensorBase' objects}\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method builtins.iter}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'dim' of 'torch._C.TensorBase' objects}\n",
      "        6    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'values' of 'dict' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'add' of 'set' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {function _ParameterMeta.__instancecheck__ at 0xfffeb2109ab0}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from shared_utils import _grid_lens\n",
    "\n",
    "# Define batch sizes to test\n",
    "#batch_sizes = [1, 10, 20, 40, 60, 80, 100, 150, 200, 400, 512, 1024]\n",
    "batch_sizes = torch.arange(1, 2, 2)\n",
    "# Arrays to store timing results\n",
    "forward_times = []\n",
    "device=\"cuda\"\n",
    "\n",
    "from catalog_manager import CatalogManager\n",
    "\n",
    "\n",
    "my_catalog = CatalogManager(catalog_name_input=\"SIS_10e7_sub_train\")\n",
    "config_list=my_catalog.catalog[\"SL_systems\"][0:]\n",
    "\n",
    "\n",
    "# Loop through batch sizes\n",
    "for batch_size in batch_sizes:\n",
    "    #print(f\"Testing batch size {batch_size}...\")\n",
    "    \n",
    "    # Clear cache\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    # Create system with batch_size\n",
    "    grid = _grid_lens(6, 1000, device=device)\n",
    "    grid = grid.unsqueeze(0).repeat(batch_size, 1, 1, 1)\n",
    "    config_list=my_catalog.catalog[\"SL_systems\"][0: batch_size]\n",
    "    \n",
    "    lensing_system = LensingSystem(config_list, device=device)\n",
    "    \n",
    "    # Time the forward pass\n",
    "    start_time = time.time()\n",
    "    image = lensing_system(grid)\n",
    "    torch.cuda.synchronize()  # Make sure GPU completes\n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    # Store timing result\n",
    "    forward_times.append(elapsed)\n",
    "    #print(f\"  Forward pass took {elapsed:.4f} seconds\")\n",
    "    \n",
    "    # Clean up\n",
    "    del lensing_system, grid, image, config_list\n",
    "\n",
    "# Plot results\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(batch_sizes, forward_times, 'o-')\n",
    "# plt.xlabel('Batch Size')\n",
    "# plt.ylabel('Time (seconds)')\n",
    "# plt.title('Forward Pass Time vs Batch Size')\n",
    "# plt.grid(True)\n",
    "# plt.savefig('batch_timing.png')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "batch_size = 2\n",
    "grid = _grid_lens(6, 2000, device=device)\n",
    "grid = grid.unsqueeze(0).repeat(batch_size, 1, 1, 1)\n",
    "config_list = [one_image_dict] * batch_size\n",
    "\n",
    "lensing_system = LensingSystem(config_list, device=device)\n",
    "\n",
    "# Time the forward pass\n",
    "%prun image = lensing_system(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lensing_system = LensingSystem(config_list, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running batched\n",
      " finished batched\n",
      "running non batched\n",
      "finished non batched\n",
      "Average batched execution time: 8.5191 seconds\n",
      "Average non-batched execution time: 11.0849 seconds\n",
      "torch.Size([2, 2000, 2000])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 400x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         593538 function calls (494995 primitive calls) in 3.367 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "     2015    1.298    0.001    1.298    0.001 {built-in method torch.tensor}\n",
      "    42282    0.554    0.000    0.555    0.000 {built-in method torch.as_tensor}\n",
      "     2005    0.452    0.000    0.470    0.000 module.py:472(__init__)\n",
      "     2000    0.328    0.000    1.585    0.001 2768220853.py:25(__init__)\n",
      "    24049    0.139    0.000    0.276    0.000 module.py:1897(__setattr__)\n",
      "60376/2000    0.130    0.000    0.793    0.000 util.py:4(recursive_to_tensor)\n",
      "237295/213222    0.074    0.000    0.156    0.000 {built-in method builtins.isinstance}\n",
      "    24049    0.066    0.000    0.089    0.000 parameter.py:10(__instancecheck__)\n",
      "16094/2000    0.062    0.000    0.788    0.000 util.py:7(<dictcomp>)\n",
      "    12007    0.053    0.000    0.053    0.000 {method 'to' of 'torch._C.TensorBase' objects}\n",
      "        2    0.039    0.019    0.878    0.439 271530330.py:70(build_param_tensor)\n",
      "        1    0.027    0.027    3.367    3.367 2877471766.py:11(__init__)\n",
      "    74145    0.019    0.000    0.019    0.000 {method 'get' of 'dict' objects}\n",
      "        1    0.016    0.016    0.905    0.905 271530330.py:35(process_configs)\n",
      "     4000    0.014    0.000    0.014    0.000 module.py:1880(__getattr__)\n",
      "     2005    0.013    0.000    0.013    0.000 {built-in method torch._C._log_api_usage_once}\n",
      "     2000    0.011    0.000    0.031    0.000 module.py:630(add_module)\n",
      "    24049    0.010    0.000    0.010    0.000 {function _ParameterMeta.__instancecheck__ at 0xfffeb2109ab0}\n",
      "     2000    0.008    0.000    0.017    0.000 {built-in method builtins.hasattr}\n",
      "     2000    0.006    0.000    0.042    0.000 container.py:407(append)\n",
      "    16026    0.005    0.000    0.005    0.000 {built-in method builtins.getattr}\n",
      "     2000    0.004    0.000    0.473    0.000 2768220853.py:12(__init__)\n",
      "     2000    0.004    0.000    0.420    0.000 util.py:16(<listcomp>)\n",
      "4002/2002    0.004    0.000    0.005    0.000 {built-in method builtins.len}\n",
      "     4000    0.003    0.000    0.004    0.000 util.py:12(<genexpr>)\n",
      "    16095    0.003    0.000    0.003    0.000 {method 'items' of 'dict' objects}\n",
      "        1    0.003    0.003    0.003    0.003 2877471766.py:55(<listcomp>)\n",
      "        1    0.003    0.003    0.795    0.795 2877471766.py:26(<listcomp>)\n",
      "      208    0.002    0.000    0.008    0.000 ipkernel.py:775(_clean_thread_parent_frames)\n",
      "      104    0.002    0.000    0.002    0.000 threading.py:1478(enumerate)\n",
      "      728    0.002    0.000    0.002    0.000 threading.py:1145(ident)\n",
      "     2000    0.002    0.000    0.003    0.000 container.py:341(__len__)\n",
      "        1    0.002    0.002    0.002    0.002 2877471766.py:29(<listcomp>)\n",
      "     9141    0.001    0.000    0.001    0.000 {method 'append' of 'list' objects}\n",
      "      104    0.001    0.000    0.003    0.000 ipkernel.py:790(<setcomp>)\n",
      "     2002    0.001    0.000    0.001    0.000 {method 'values' of 'collections.OrderedDict' objects}\n",
      "     2000    0.001    0.000    0.004    0.000 {built-in method builtins.all}\n",
      "        1    0.001    0.001    0.004    0.004 2291391825.py:171(__init__)\n",
      "        1    0.001    0.001    0.001    0.001 2877471766.py:30(<listcomp>)\n",
      "        1    0.001    0.001    0.906    0.906 271530330.py:8(__init__)\n",
      "        1    0.000    0.000    3.367    3.367 <string>:1(<module>)\n",
      "        1    0.000    0.000    0.003    0.003 2291391825.py:31(__init__)\n",
      "        1    0.000    0.000    3.367    3.367 {built-in method builtins.exec}\n",
      "      208    0.000    0.000    0.000    0.000 {method 'values' of 'dict' objects}\n",
      "      416    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}\n",
      "      104    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.RLock' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'pow' of 'torch._C.TensorBase' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch.log}\n",
      "        2    0.000    0.000    0.000    0.000 2768220853.py:219(__del__)\n",
      "        1    0.000    0.000    0.000    0.000 _tensor.py:33(wrapped)\n",
      "        2    0.000    0.000    0.000    0.000 2291391825.py:5(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 container.py:306(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 module.py:1898(remove_from)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'clear' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._has_torch_function}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'clear' of 'set' objects}"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from shared_utils import recursive_to_tensor, _grid_lens\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from lensing_system import LensingSystem as LensingSystemNonBatched\n",
    "\n",
    "device=\"cuda\"\n",
    "\n",
    "\n",
    "\n",
    "#one_image_dict=recursive_to_tensor(one_image_dict, device=device)\n",
    "\n",
    "batch_size=2000\n",
    "grid = _grid_lens(6, 100, device=device, dtype=torch.float32)\n",
    "grid = grid.unsqueeze(0).repeat(batch_size, 1, 1, 1) if len(grid.shape) == 3 else grid.repeat(batch_size, 1, 1, 1)\n",
    "\n",
    "from catalog_manager import CatalogManager\n",
    "import time\n",
    "my_catalog = CatalogManager(catalog_name_input=\"SIS_10e7_sub_train\")\n",
    "config_list=my_catalog.catalog[\"SL_systems\"][0: batch_size]\n",
    "config_list=[recursive_to_tensor(config, device) for config in config_list]\n",
    "\n",
    "\n",
    "def run_batched():\n",
    "    print(\"running batched\")\n",
    "    #empty gpu cache\n",
    "    torch.cuda.empty_cache()\n",
    "    #with torch.no_grad():\n",
    "    %prun lensing_system=LensingSystem(config_list, device=device, dtype=torch.float32)\n",
    "    image=lensing_system(grid)\n",
    "    print(\"finished batched\")\n",
    "    return image\n",
    "\n",
    "def run_non_batched():\n",
    "    print(\"running non batched\")\n",
    "    #empty gpu cache\n",
    "    torch.cuda.empty_cache()\n",
    "    #with torch.no_grad():\n",
    "    images=[]\n",
    "    for i in range(batch_size):\n",
    "        lensing_system=LensingSystemNonBatched(config_list[i], device=device)\n",
    "        images.append(lensing_system(grid[i]))\n",
    "    #stack the images\n",
    "    image=torch.stack(images)\n",
    "    print(\"finished non batched\")\n",
    "    return image\n",
    "\n",
    "\n",
    "# Measure running time for batched execution\n",
    "num_repeats = 1\n",
    "batched_times = []\n",
    "non_batched_times = []\n",
    "\n",
    "for _ in range(num_repeats):\n",
    "    # Measure running time for batched execution\n",
    "    start_time_batched = time.time()\n",
    "    images = run_batched()\n",
    "    elapsed_time_batched = time.time() - start_time_batched\n",
    "    batched_times.append(elapsed_time_batched)\n",
    "\n",
    "    # Measure running time for non-batched execution\n",
    "    start_time_non_batched = time.time()\n",
    "    images_non_batched = run_non_batched()\n",
    "    elapsed_time_non_batched = time.time() - start_time_non_batched\n",
    "    non_batched_times.append(elapsed_time_non_batched)\n",
    "\n",
    "# Calculate average execution times\n",
    "avg_batched_time = sum(batched_times) / num_repeats\n",
    "avg_non_batched_time = sum(non_batched_times) / num_repeats\n",
    "\n",
    "print(f\"Average batched execution time: {avg_batched_time:.4f} seconds\")\n",
    "print(f\"Average non-batched execution time: {avg_non_batched_time:.4f} seconds\")\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "#plt.imshow(images[0].cpu().detach().numpy())\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "asdf§"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
